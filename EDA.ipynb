{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19's Impact on Healthcare Accessibility\n",
    "### By: Tristan Call and Maria Elena Aviles-Baquero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS\n",
    "# 1. Focus on Washington (for now aka. generalize code (as always))\n",
    "# 2. create default values\n",
    "\n",
    "# data analysis functions:\n",
    "# group_by()\n",
    "# get_column() - MyPyTable\n",
    "# plotting - whatever we used in class\n",
    "    # save_graph() function\n",
    "# output result files (? TBD)\n",
    "\n",
    "# summary_stats from MyPyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.plot_utils\n",
    "importlib.reload(mysklearn.plot_utils)\n",
    "import mysklearn.plot_utils as plot_utils\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate Data into Useable Format\n",
    "The first thing we need to do is grab the data from the sas file and manipulate it into a format and size which is workable with our very much not optimized dataset. Part of this involves dropping rows with NaNs in them ahead of time. Overall we aim to go from about 70,000 results to a more reasonable < 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TBIRTH_YEAR  EGENDER  RHISPANIC  RRACE  EEDUC  INCOME  DELAY  NOTGET\n",
      "1          1969.0      2.0        1.0    1.0    7.0     6.0    1.0     2.0\n",
      "2          1959.0      2.0        1.0    1.0    7.0     4.0    1.0     1.0\n",
      "4          1967.0      1.0        1.0    1.0    4.0     6.0    2.0     2.0\n",
      "5          1965.0      1.0        1.0    1.0    7.0     6.0    2.0     2.0\n",
      "6          1962.0      2.0        1.0    2.0    4.0     1.0    2.0     2.0\n",
      "...           ...      ...        ...    ...    ...     ...    ...     ...\n",
      "4993       1964.0      2.0        1.0    1.0    4.0     1.0    2.0     2.0\n",
      "4994       1984.0      1.0        1.0    1.0    4.0     7.0    1.0     1.0\n",
      "4995       1973.0      1.0        1.0    1.0    6.0     8.0    2.0     2.0\n",
      "4997       1976.0      2.0        1.0    1.0    3.0     3.0    1.0     1.0\n",
      "4999       1958.0      2.0        1.0    1.0    7.0     5.0    2.0     2.0\n",
      "\n",
      "[4063 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Grab the data\n",
    "week21_filename = os.path.join(\"input_data\", \"pulse2020_puf_21.sas7bdat\")\n",
    "iterator = pd.read_sas(week21_filename, chunksize=5000)\n",
    "alldata = []\n",
    "for chunk in iterator:\n",
    "    alldata.append(chunk)\n",
    "\n",
    "relevant_attributes = [\"TBIRTH_YEAR\", \"EGENDER\", \"RHISPANIC\", \"RRACE\", \"EEDUC\", \"INCOME\", \"DELAY\", \"NOTGET\"]\n",
    "\n",
    "# Grab a chunk of data with the attributes we are interested in, minus Nans, and save to a local file\n",
    "data = alldata[0][[\"TBIRTH_YEAR\", \"EGENDER\", \"RHISPANIC\", \"RRACE\", \"EEDUC\", \"INCOME\", \"DELAY\", \"NOTGET\"]]\n",
    "working_data_filename = os.path.join(\"input_data\", \"week21_working.csv\")\n",
    "nafree_data = data.dropna()\n",
    "print(nafree_data)\n",
    "nafree_data.to_csv(working_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysklearn.mypytable.MyPyTable at 0x7f06c0ca6a30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a mypytable for future analysis\n",
    "overall_table = MyPyTable()\n",
    "overall_table.load_from_file(working_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group-by visualizations\n",
    "    # Race, Age, and Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "In this section we will classify our results using our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
